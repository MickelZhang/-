本项目是一个关于python使用过程中的问题点记录：
以下为相关的参考：
https://python3-cookbook.readthedocs.io/zh_CN/latest/c01/p10_remove_duplicates_from_seq_order.html  
https://docs.python.org/zh-cn/3.6/reference/expressions.html
http://github.phodal.com/  
https://github.com/521xueweihan/HelloGitHub 
https://github.com/keon/algorithms 
https://github.com/TheAlgorithms 

查找算法：
https://www.cnblogs.com/maybe2030/p/4715035.html 
顺序查找
二分查找
差值查找
斐波那契查找
树表查找
分块查找
哈希查找

排序算法


效率提升：

1.首先分析程序的瓶颈在什么地方
A::::cProfile 
https://docs.python.org/zh-cn/3/library/profile.html  官方教程
https://www.ibm.com/developerworks/cn/linux/l-cn-python-optim/  
http://love67.net/2016/03/08/python-profile  
B:::: Timeit 查看程序运行多次的时间

C::: https://www.cnblogs.com/nisen/p/6076082.html  

2.针对瓶颈给出解决方案


3.编写代码时，基本的效率提升手段
https://zhuanlan.zhihu.com/p/53283309
https://zhuanlan.zhihu.com/p/157793139 
https://time.geekbang.org/column/article/189201


http://www.uml.org.cn/python/201801302.asp   19个高效小技巧


技巧：列表拷贝使用list()新建而不要使用copy模块。基于性能来说copy模块在复制数据的时候悬疑先对数据类型判断，而list内奸的方法则不需要
大数据处理时，生成器比列表推导式更快 （列表推导式一次性加载所有的数据到内存中），生成器则不会讲所有的值一次性加到内存中，采用延迟计算的方式
每次处理一个对象，在用的时候创建临时区，遍历结束后删除清空临时去，减少内存开销   
生成器的使用场景：第一次调用之后会清空缓存区，因此当只需要使用一次数据时，采用生成器的方法比较合适，若多次使用生产的数据则建议使用列表推导式
（如你想读取文件并且返回每行中的字符数量，用列表生成式就要保证内存中有这个文件的所有行才能做操作）
https://www.cnblogs.com/shaosks/p/7084748.html  
https://blog.csdn.net/fly910905/article/details/76286080 

字符串拼接使用join而不是+   join效率高   

python3.6以后的版本使用F-string 替代format做格式化操作   前者稍微快以点

in 查找list操作时，将list转换成set更快  （list时间复杂度为O（n）,set和dict是O（1））
set dict都是采用hash实现，查找的时间复杂度为O(1)
但是并非所有的情况都可以将list转为set来进行查找：由于set使用hash实现，必须保持key的唯一性，同时，list可保持一定顺序，
而set是无序的，因此，如果被查找的list中存在重复值，且不允许去重查找，且查找方式与顺序有关，则此时不适合将list转为set来做查找操作。

多采用enumerate来获取下标，而不是zip
enumerate方法遍历元素不仅效率高，而且可读性好。与上面的迭代器和推导式的关系差不多

defaultdict  对一些字典的操作可能更快


是否可以切片，实际上是看对应的对象有没有相关的方法
https://blog.csdn.net/xpresslink/article/details/77727507  




github使用指南：https://docs.github.com/cn/free-pro-team@latest/github/administering-a-repository/setting-repository-visibility 


空值判断：
https://www.jianshu.com/p/a0d273550f70 
